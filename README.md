# An√°lisis de Sentimientos en Rese√±as de Productos Deportivos üéæ

## Descripci√≥n del Proyecto ‚úçüèº

Este proyecto explora el an√°lisis de sentimientos en rese√±as de productos de deporte y aire libre de Amazon, enfoc√°ndose en metodolog√≠as de procesamiento de lenguaje natural (NLP). Se prioriza el desarrollo de un marco de trabajo s√≥lido y justificado para la construcci√≥n de modelos de an√°lisis de sentimiento, enfatizando en el proceso sobre la perfecci√≥n de las m√©tricas.

## Objetivos üë©üèº‚Äçüíª

- Aplicar pr√°cticas sistem√°ticas para resolver desaf√≠os de NLP.
- Realizar un an√°lisis de sentimientos completo, desde la adquisici√≥n hasta el procesamiento y an√°lisis de datos.
- Evaluar modelos de machine learning y deep learning en la clasificaci√≥n de sentimientos.
- Extraer y discutir insights, con √©nfasis en el proceso y los aprendizajes obtenidos.

## Estructura del Repositorio üóÇÔ∏è

- `data/`: Conjuntos de datos y estructura.
- `img/`: Gr√°ficos y visualizaciones.
- `src/`: Notebooks y scripts de c√≥digo fuente.
    - `utils.py`: Funciones de utilidad y herramientas complementarias.
    - `preprocessing.py`: Scripts de preprocesamiento de datos.
- `models/`: Modelos entrenados y procedimientos de modelado.
- `requirements.txt`: Lista de dependencias necesarias para el proyecto.

## Gu√≠a de Uso üìë

1. Clone el repositorio en su entorno local.
2. Instale las dependencias indicadas en `requirements.txt`.
3. Descargue los datos siguiendo las instrucciones en el script/notebook correspondiente.
4. Ejecute los notebooks en secuencia para replicar el flujo de trabajo y los resultados.

## Mejoras y Reflexiones üß†

Reconozco la oportunidad de modularizar m√°s el notebook `3_entrenamiento_y_testeo_modelo.ipynb`, para una mejor comprensi√≥n y mantenimiento del c√≥digo. Esta mejora est√° pendiente y es un enfoque para el futuro desarrollo del proyecto. Adem√°s, hay un continuo esfuerzo por optimizar los modelos y el preprocesamiento de datos para refinar los an√°lisis realizados.

El proyecto ha sido una plataforma para reafirmar la importancia cr√≠tica de un preprocesamiento minucioso y la selecci√≥n de caracter√≠sticas en NLP. La experimentaci√≥n con diferentes modelos ha validado la eficiencia de la Regresi√≥n Log√≠stica y ha mostrado el potencial del aprendizaje profundo en la identificaci√≥n de patrones complejos en texto. Las lecciones aprendidas aqu√≠ son de gran valor y ser√°n aplicadas en investigaciones futuras.